{"cells":[{"cell_type":"markdown","metadata":{},"source":["# üìù Exercise M3.01\n","\n","The goal is to write an exhaustive search to find the best parameters\n","combination maximizing the model generalization performance.\n","\n","Here we use a small subset of the Adult Census dataset to make the code\n","faster to execute. Once your code works on the small subset, try to\n","change `train_size` to a larger value (e.g. 0.8 for 80% instead of\n","20%)."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","from sklearn.model_selection import train_test_split\n","\n","adult_census = pd.read_csv(\"../datasets/adult-census.csv\")\n","\n","target_name = \"class\"\n","target = adult_census[target_name]\n","data = adult_census.drop(columns=[target_name, \"education-num\"])\n","\n","data_train, data_test, target_train, target_test = train_test_split(\n","    data, target, train_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"id":"b315b092","metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","from sklearn.model_selection import train_test_split\n","\n","adult_census = pd.read_csv()\n","\n","target_name = 'class'\n","y = adult_census[target_name]\n","X = adult_census.drop(columns = [target, 'education-num'])\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.compose import make_column_selector as selector\n","from sklearn.preprocessing import OrdinalEncoder\n","\n","categorical_preprocessor = OrdinalEncoder(handle_unknown=\"use_encoded_value\",\n","                                          unknown_value=-1)\n","preprocessor = ColumnTransformer(\n","    [('cat_preprocessor', categorical_preprocessor,\n","      selector(dtype_include=object))],\n","    remainder='passthrough', sparse_threshold=0)\n","\n","from sklearn.ensemble import HistGradientBoostingClassifier\n","from sklearn.pipeline import Pipeline\n","\n","model = Pipeline([\n","    (\"preprocessor\", preprocessor),\n","    (\"classifier\", HistGradientBoostingClassifier(random_state=42))\n","])"]},{"cell_type":"code","execution_count":2,"id":"edd25866","metadata":{},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.compose import make_column_selector as selector\n","from sklearn.preprocessing import OrdinalEncoder\n","\n","cat_preprocessor = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n","\n","preprocessor = ColumnTransformer(\n","    [('cat_preprocessor', cat_preprocessor, selector(dtype_include=object))],\n","    remainder='passthrough', sparse_threshold=0\n",")"]},{"cell_type":"code","execution_count":3,"id":"bf5246d5","metadata":{},"outputs":[],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.ensemble import HistGradientBoostingClassifier\n","\n","model = Pipeline([\n","    ('preprocessor', preprocessor),\n","    ('classifier', HistGradientBoostingClassifier(random_state=42))\n","])"]},{"cell_type":"markdown","metadata":{},"source":["\n","Use the previously defined model (called `model`) and using two nested `for`\n","loops, make a search of the best combinations of the `learning_rate` and\n","`max_leaf_nodes` parameters. In this regard, you will need to train and test\n","the model by setting the parameters. The evaluation of the model should be\n","performed using `cross_val_score` on the training set. We will use the\n","following parameters search:\n","- `learning_rate` for the values 0.01, 0.1, 1 and 10. This parameter controls\n","  the ability of a new tree to correct the error of the previous sequence of\n","  trees\n","- `max_leaf_nodes` for the values 3, 10, 30. This parameter controls the\n","  depth of each tree."]},{"cell_type":"code","execution_count":6,"id":"6aca46aa","metadata":{},"outputs":[{"data":{"text/plain":["{'memory': None,\n"," 'steps': [('preprocessor',\n","   ColumnTransformer(remainder='passthrough', sparse_threshold=0,\n","                     transformers=[('cat_preprocessor',\n","                                    OrdinalEncoder(handle_unknown='use_encoded_value',\n","                                                   unknown_value=-1),\n","                                    <sklearn.compose._column_transformer.make_column_selector object at 0x0000022E6F5B8A00>)])),\n","  ('classifier', HistGradientBoostingClassifier(random_state=42))],\n"," 'verbose': False,\n"," 'preprocessor': ColumnTransformer(remainder='passthrough', sparse_threshold=0,\n","                   transformers=[('cat_preprocessor',\n","                                  OrdinalEncoder(handle_unknown='use_encoded_value',\n","                                                 unknown_value=-1),\n","                                  <sklearn.compose._column_transformer.make_column_selector object at 0x0000022E6F5B8A00>)]),\n"," 'classifier': HistGradientBoostingClassifier(random_state=42),\n"," 'preprocessor__n_jobs': None,\n"," 'preprocessor__remainder': 'passthrough',\n"," 'preprocessor__sparse_threshold': 0,\n"," 'preprocessor__transformer_weights': None,\n"," 'preprocessor__transformers': [('cat_preprocessor',\n","   OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1),\n","   <sklearn.compose._column_transformer.make_column_selector at 0x22e6f5b8a00>)],\n"," 'preprocessor__verbose': False,\n"," 'preprocessor__verbose_feature_names_out': True,\n"," 'preprocessor__cat_preprocessor': OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1),\n"," 'preprocessor__cat_preprocessor__categories': 'auto',\n"," 'preprocessor__cat_preprocessor__dtype': numpy.float64,\n"," 'preprocessor__cat_preprocessor__encoded_missing_value': nan,\n"," 'preprocessor__cat_preprocessor__handle_unknown': 'use_encoded_value',\n"," 'preprocessor__cat_preprocessor__max_categories': None,\n"," 'preprocessor__cat_preprocessor__min_frequency': None,\n"," 'preprocessor__cat_preprocessor__unknown_value': -1,\n"," 'classifier__categorical_features': None,\n"," 'classifier__class_weight': None,\n"," 'classifier__early_stopping': 'auto',\n"," 'classifier__interaction_cst': None,\n"," 'classifier__l2_regularization': 0.0,\n"," 'classifier__learning_rate': 0.1,\n"," 'classifier__loss': 'log_loss',\n"," 'classifier__max_bins': 255,\n"," 'classifier__max_depth': None,\n"," 'classifier__max_iter': 100,\n"," 'classifier__max_leaf_nodes': 31,\n"," 'classifier__min_samples_leaf': 20,\n"," 'classifier__monotonic_cst': None,\n"," 'classifier__n_iter_no_change': 10,\n"," 'classifier__random_state': 42,\n"," 'classifier__scoring': 'loss',\n"," 'classifier__tol': 1e-07,\n"," 'classifier__validation_fraction': 0.1,\n"," 'classifier__verbose': 0,\n"," 'classifier__warm_start': False}"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["model.get_params()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["depth: 3, learning_rate: 0.01, mean: 0.813\n","depth: 3, learning_rate: 0.1, mean: 0.866\n","depth: 3, learning_rate: 1, mean: 0.871\n","depth: 3, learning_rate: 10, mean: 0.346\n","\n","\n","depth: 10, learning_rate: 0.01, mean: 0.848\n","depth: 10, learning_rate: 0.1, mean: 0.874\n","depth: 10, learning_rate: 1, mean: 0.864\n","depth: 10, learning_rate: 10, mean: 0.388\n","\n","\n","depth: 30, learning_rate: 0.01, mean: 0.849\n","depth: 30, learning_rate: 0.1, mean: 0.874\n","depth: 30, learning_rate: 1, mean: 0.863\n","depth: 30, learning_rate: 10, mean: 0.402\n","\n","\n"]}],"source":["from sklearn.model_selection import cross_val_score\n","\n","learning_rate = [0.01, 0.1, 1, 10]\n","max_depth = [3, 10, 30]\n","\n","score_dict = {'depth' : [], 'learning_rate' : [], 'mean' : []}\n","\n","for depth in max_depth:\n","    for learning in learning_rate:\n","        model.set_params(classifier__learning_rate = learning, classifier__max_depth = depth)\n","        scores = cross_val_score(model, data, target)\n","        score_dict['depth'].append(depth)\n","        score_dict['learning_rate'].append(learning)\n","        score_dict['mean'].append(round(scores.mean(),3))\n","        print(f'depth: {depth}, learning_rate: {learning}, mean: {scores.mean():.3f}')\n","    print('\\n')"]},{"cell_type":"code","execution_count":18,"id":"da7a308b","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>depth</th>\n","      <th>learning_rate</th>\n","      <th>mean</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5</th>\n","      <td>10</td>\n","      <td>0.10</td>\n","      <td>0.874</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>30</td>\n","      <td>0.10</td>\n","      <td>0.874</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1.00</td>\n","      <td>0.871</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>0.10</td>\n","      <td>0.866</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>10</td>\n","      <td>1.00</td>\n","      <td>0.864</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>30</td>\n","      <td>1.00</td>\n","      <td>0.863</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>30</td>\n","      <td>0.01</td>\n","      <td>0.849</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10</td>\n","      <td>0.01</td>\n","      <td>0.848</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>0.01</td>\n","      <td>0.813</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>30</td>\n","      <td>10.00</td>\n","      <td>0.402</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>10</td>\n","      <td>10.00</td>\n","      <td>0.388</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>10.00</td>\n","      <td>0.346</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    depth  learning_rate   mean\n","5      10           0.10  0.874\n","9      30           0.10  0.874\n","2       3           1.00  0.871\n","1       3           0.10  0.866\n","6      10           1.00  0.864\n","10     30           1.00  0.863\n","8      30           0.01  0.849\n","4      10           0.01  0.848\n","0       3           0.01  0.813\n","11     30          10.00  0.402\n","7      10          10.00  0.388\n","3       3          10.00  0.346"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["pd.DataFrame(score_dict).sort_values('mean', ascending = False)"]},{"cell_type":"markdown","metadata":{},"source":["\n","Now use the test set to score the model using the best parameters\n","that we found using cross-validation in the training set."]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["depth: 10, learning_rate: 0.01, scores: 0.8738 +- 0.0022\n","depth: 30, learning_rate: 0.01, scores: 0.8736 +- 0.0024\n"]}],"source":["from sklearn.model_selection import cross_validate\n","\n","max_depth = [10, 30]\n","\n","for depth in max_depth:\n","    model.set_params(classifier__learning_rate = 0.10, classifier__max_depth = depth)\n","    cv_result = cross_validate(model, data, target)\n","    scores = cv_result['test_score']\n","    \n","    print(f'depth: {depth}, learning_rate: 0.01, scores: {scores.mean():.4f} +- {scores.std():.4f}')\n"]},{"cell_type":"code","execution_count":null,"id":"bd009244","metadata":{},"outputs":[],"source":[]}],"metadata":{"jupytext":{"encoding":"# -*- coding: utf-8 -*-","main_language":"python"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.4"},"nbreset":"https://github.com/INRIA/scikit-learn-mooc/raw/main/notebooks/parameter_tuning_ex_02.ipynb"},"nbformat":4,"nbformat_minor":5}
